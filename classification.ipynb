{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://kritikseth.github.io/redirect\" target=\"_parent\"><img src=\"https://raw.githack.com/kritikseth/kritikseth/master/redirect.svg\" alt=\"Kritik Seth\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import geom\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.power import TTestIndPower, ttest_power\n",
    "\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from plotly import tools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gower\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, roc_auc_score, classification_report, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "\n",
    "R_STATE = 18714836 # random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transformed_fps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'CPU Name', 'GPU Name','GPU Open GL','CPU Model','Dataset'] #GPU Open GL has only one value\n",
    "label_cols = ['CPU Brand', 'CPU Series',\n",
    "              'CPU Type', 'CPU Multiplier Unlocked',\n",
    "              'GPU Architecture', 'GPU Bus', 'GPU Memory Type',\n",
    "              'GPU Open CL','GPU Shader Model', 'GPU Vulkan', 'Game',\n",
    "              ]\n",
    "\n",
    "auto_ordinal_cols = ['Game Resolution', 'CPU Base Clock', 'GPU Direct X'] # Questionable: CPU Base Clock, \n",
    "\n",
    "#df['CPU Model'] = df['CPU Model'].replace({'X2': 0, '3': 1, 'i3': 1, '5': 2, 'i5': 2, '7': 3, 'i7': 3, '9': 4, 'Threadripper': 5})\n",
    "\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict_resolution = {720:0,1080:1,1440:2}\n",
    "df['Game Resolution'] = df['Game Resolution'].map(enc_dict_resolution)\n",
    "\n",
    "enc_dict_CPU_base_clock = {100:0,133:1,200:2}\n",
    "df['CPU Base Clock'] = df['CPU Base Clock'].map(enc_dict_CPU_base_clock)\n",
    "\n",
    "df['GPU Direct X'] = df['GPU Direct X'].astype(str)\n",
    "enc_dict_direct = {'12':0,'12 Ultimate':1}\n",
    "df['GPU Direct X'] = df['GPU Direct X'].map(enc_dict_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_curve(model, xtrain, ytrain, xtest, ytest):\n",
    "\n",
    "    # Creating visualization with the readable labels\n",
    "    visualizer = ROCAUC(model)\n",
    "                                        \n",
    "    # Fitting to the training data first then scoring with the test data                                    \n",
    "    visualizer.fit(xtrain, ytrain)\n",
    "    visualizer.score(xtest, ytest)\n",
    "    visualizer.show()\n",
    "    \n",
    "    return visualizer\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "    \n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        \n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full dataset\n",
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
    "                      warm_start=False)\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "rfc.fit(X_train, y_train) \n",
    "\n",
    "y_pred=rfc.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with 25 components\n",
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
    "                      warm_start=False)\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "steps = [('pca', PCA(n_components=25)), ('m', rfc)]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with 30 components\n",
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
    "                      warm_start=False)\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "steps = [('pca', PCA(n_components=30)), ('m', rfc)]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm full dataset\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 components\n",
    "\n",
    "lgbm_full = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "steps = [('pca', PCA(n_components=25)), ('m', lgbm_full)]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 components\n",
    "\n",
    "lgbm_full = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
    "df1=df.drop(\"Game Settings\",axis=1)\n",
    "X = df1\n",
    "y = df['Game Settings']\n",
    "steps = [('pca', PCA(n_components=30)), ('m', lgbm_full)]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "target_names = ['low', 'med', 'high','max']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://kritikseth.github.io/redirect\" target=\"_parent\"><img src=\"https://raw.githack.com/kritikseth/kritikseth/master/redirect.svg\" alt=\"Kritik Seth\"/></a>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

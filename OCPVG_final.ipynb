{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://kritikseth.github.io/redirect\" target=\"_parent\"><img src=\"https://raw.githack.com/kritikseth/kritikseth/master/redirect.svg\" alt=\"Kritik Seth\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandasql import sqldf\n",
        "\n",
        "import math\n",
        "from scipy import stats\n",
        "from scipy.stats import geom\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.stats.power import TTestIndPower, ttest_power\n",
        "\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import seaborn as sns\n",
        "from plotly import tools\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import gower\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error, roc_auc_score, classification_report, mean_absolute_error\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
        "\n",
        "R_STATE = 18714836 # random state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgvHpPspyVkA",
        "outputId": "a1635b3a-1577-4c0a-e153-a365fed15b52"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNpc9Lt8ZWPb"
      },
      "source": [
        "## Data Loading and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph-6yvUSyP4f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Capstone/fps_videogames.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPXw9D-OY6jF"
      },
      "outputs": [],
      "source": [
        "rename = {'CpuName': 'CPU Name', 'CpuNumberOfCores': 'CPU Cores', 'CpuNumberOfThreads': 'CPU Threads',\n",
        "          'CpuBaseClock': 'CPU Base Clock', 'CpuCacheL1': 'CPU Cache L1', 'CpuCacheL2': 'CPU Cache L2',\n",
        "          'CpuCacheL3': 'CPU Cache L3', 'CpuDieSize': 'CPU Die Size', 'CpuFrequency': 'CPU Frequency',\n",
        "          'CpuMultiplier': 'CPU Multiplier', 'CpuMultiplierUnlocked': 'CPU Multiplier Unlocked',\n",
        "          'CpuProcessSize': 'CPU Process Size', 'CpuTDP': 'CPU TDP', 'CpuNumberOfTransistors': 'CPU Transistors',\n",
        "          'CpuTurboClock': 'CPU Turbo Clock',\n",
        "          'GpuName': 'GPU Name', 'GpuArchitecture': 'GPU Architecture', 'GpuBandwidth': 'GPU Bandwidth',\n",
        "          'GpuBaseClock': 'GPU Base Clock', 'GpuBoostClock': 'GPU Boost Clock', '\\'GpuBus': 'GPU Bus',\n",
        "          'GpuNumberOfComputeUnits': 'GPU Compute Units', 'GpuDieSize': 'GPU Die Size', 'GpuDirectX': 'GPU Direct X',\n",
        "          'GpuNumberOfExecutionUnits': 'GPU Execution Units', 'GpuFP32Performance': 'GPU FP32 Performance',\n",
        "          'GpuMemoryBus': 'GPU Memory Bus', 'GpuMemorySize': 'GPU Memory Size', 'GpuMemoryType': 'GPU Memory Type',\n",
        "          'GpuOpenCL': 'GPU Open CL', 'GpuOpenGL': 'GPU Open GL', 'GpuPixelRate': 'GPU Pixel Rate', 'GpuProcessSize': 'GPU Process Size',\n",
        "          'GpuNumberOfROPs': 'GPU Number of ROPs', 'GpuShaderModel': 'GPU Shader Model', 'GpuNumberOfShadingUnits': 'GPU Shading Units',\n",
        "          'GpuNumberOfTMUs': 'GPU TMUs', 'GpuTextureRate': 'GPU Texture Rate', 'GpuNumberOfTransistors': 'GPU Transistors', 'GpuVulkan': 'GPU Vulkan',\n",
        "          'GameName': 'Game', 'GameResolution': 'Game Resolution', 'GameSetting': 'Game Settings'}\n",
        "\n",
        "df.rename(columns=rename, inplace=True)\n",
        "\n",
        "df['CPU Name'] = df['CPU Name'].apply(lambda x: x.replace('-', ' '))\n",
        "df['CPU Brand'] = df['CPU Name'].apply(lambda x: x.split(' ')[0])\n",
        "\n",
        "df['CPU Type'] = df['CPU Name'].apply(lambda x: re.findall('[a-zA-Z]+', x)[-1].upper() if x[-1].isalpha() else 'Normal')\n",
        "df['CPU Name'] = df['CPU Name'].apply(lambda x: x.replace(re.findall('[a-zA-Z]+', x)[-1], '', -1).strip() if x[-1].isalpha() else x)\n",
        "\n",
        "df['CPU Model'] = df['CPU Name']\n",
        "df['CPU Model'] = df.apply(lambda x : x['CPU Model'].replace(str(x['CPU Brand']), '').strip(), axis=1)\n",
        "\n",
        "cpu_series = ['A4', 'A6', 'Athlon', 'Athlon 64', 'Athlon II', 'FX', 'Ryzen', 'Core', 'Pentium']\n",
        "\n",
        "for series in cpu_series:\n",
        "    df['CPU Series Temp'] = df['CPU Model'].apply(lambda x: series if series in x else 'NA')\n",
        "    ind = df[df['CPU Series Temp']==series].index\n",
        "    df.loc[ind, 'CPU Series'] = df.loc[ind, 'CPU Series Temp']\n",
        "\n",
        "df['CPU Model'] = df.apply(lambda x : x['CPU Model'].replace(str(x['CPU Series']), '').strip(), axis=1)\n",
        "df.drop(['CPU Series Temp'], axis=1, inplace=True)\n",
        "\n",
        "df['CPU Generation'] = df['CPU Model'].apply(lambda x: x.split(' ')[-1][1] if x.split(' ')[-1][0].isalpha() else x.split(' ')[-1][0]).tolist()\n",
        "\n",
        "core_ind = df[df['CPU Series']=='Core'].index\n",
        "\n",
        "df.loc[core_ind, 'CPU Generation'] = df.loc[core_ind, 'CPU Model'].apply(lambda x: x.split(' ')[-1][0]+'0' if len(x.split(' ')[-1])==3 else x.split(' ')[-1][0])\n",
        "older_gen = {'90': 1, '80': 0, '70': -1, '60': -2, '50': -3, '40': -4, '(': None}\n",
        "df['CPU Generation'] = df['CPU Generation'].replace(older_gen)\n",
        "\n",
        "df['CPU Model'] = df.apply(lambda x : x['CPU Model'].replace(str(x['CPU Model'].split(' ')[-1]), '').strip(), axis=1)\n",
        "\n",
        "df['CPU Model'] = df['CPU Model'].fillna('NA')\n",
        "df['CPU Series'] = df['CPU Series'].fillna('NA')\n",
        "df.replace({'?': None}, inplace=True)\n",
        "\n",
        "df['GPU Transistors'] = df['GPU Transistors'].astype(float)\n",
        "df['CPU Transistors'] = df['CPU Transistors'].astype(float)\n",
        "\n",
        "df['GPU Die Size'] = df['GPU Die Size'].astype(float)\n",
        "df['CPU Die Size'] = df['CPU Die Size'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfN3DqTWY7Lp"
      },
      "outputs": [],
      "source": [
        "cpu_cols = ['CPU Name', 'CPU Brand', 'CPU Model', 'CPU Series', 'CPU Generation', 'CPU Type', 'CPU Cores', 'CPU Threads',\n",
        "            'CPU Base Clock', 'CPU Cache L1', 'CPU Cache L2', 'CPU Cache L3', 'CPU Die Size','CPU Frequency', 'CPU Multiplier',\n",
        "            'CPU Multiplier Unlocked', 'CPU Process Size', 'CPU TDP', 'CPU Transistors', 'CPU Turbo Clock']\n",
        "\n",
        "cpu_detail_cols = ['CPU Brand', 'CPU Model', 'CPU Series', 'CPU Generation']\n",
        "\n",
        "gpu_cols = ['GPU Name', 'GPU Architecture', 'GPU Bandwidth', 'GPU Base Clock', 'GPU Boost Clock', 'GPU Bus', 'GPU Compute Units',\n",
        "            'GPU Die Size', 'GPU Direct X', 'GPU Execution Units', 'GPU FP32 Performance', 'GPU Memory Bus', 'GPU Memory Size',\n",
        "            'GPU Memory Type', 'GPU Open CL', 'GPU Open GL', 'GPU Pixel Rate', 'GPU Process Size', 'GPU Number of ROPs', 'GPU Shader Model',\n",
        "            'GPU Shading Units', 'GPU TMUs', 'GPU Texture Rate', 'GPU Transistors', 'GPU Vulkan']\n",
        "\n",
        "gpu_detail_cols = ['GPU Brand', 'GPU Model', 'GPU Series', 'GPU Generation']\n",
        "\n",
        "\n",
        "cpu = df[cpu_cols]\n",
        "gpu = df[gpu_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfdWyTFRh2mo"
      },
      "outputs": [],
      "source": [
        "# gpu['GPU Name Temp'] = gpu['GPU Name']\n",
        "# gpu['GPU Brand'] = gpu['GPU Name Temp'].apply(lambda x: x.split(' ')[0])\n",
        "# gpu['GPU Name Temp'] = gpu['GPU Name Temp'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
        "\n",
        "# gpu['GPU Model'] = gpu['GPU Name Temp'].apply(lambda x: x.split(' ')[0])\n",
        "# gpu['GPU Name Temp'] = gpu['GPU Name Temp'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
        "\n",
        "# gpu['GPU Series'] = gpu['GPU Name Temp'].apply(lambda x: x.split(' ')[0])\n",
        "# gpu['GPU Name Temp'] = gpu['GPU Name Temp'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
        "\n",
        "# gpu['GPU Generation'] = gpu['GPU Name Temp'].apply(lambda x: x.split(' ')[0])\n",
        "# gpu['GPU Name Temp'] = gpu['GPU Name Temp'].apply(lambda x: ' '.join(x.split(' ')[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzjwDahCgrE4"
      },
      "outputs": [],
      "source": [
        "cpu_null_cols = ['CPU Cache L3', 'CPU Die Size', 'CPU Transistors']\n",
        "gpu_null_cols = ['GPU Bandwidth', 'GPU Compute Units', 'GPU Compute Units', 'GPU Compute Units', 'GPU Die Size',\n",
        "                 'GPU Execution Units', 'GPU FP32 Performance', 'GPU Memory Bus', 'GPU Memory Size', 'GPU Memory Type',\n",
        "                 'GPU Open CL', 'GPU Shader Model', 'GPU Shading Units', 'GPU Transistors', 'GPU Vulkan']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIf-LWXVZaD9"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua9S-yLdUhWi"
      },
      "outputs": [],
      "source": [
        "def missing_values_table(df):\n",
        "    mis_val = df.isnull().sum()\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "    mis_val_table_ren_columns = mis_val_table.rename(\n",
        "    columns = {0: 'Missing Values', 1: '% of Total Values'})\n",
        "    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
        "    print(f'Your selected dataframe has {str(df.shape[1])} columns.\\nThere are {str(mis_val_table_ren_columns.shape[0])} columns that have missing values.')\n",
        "    return mis_val_table_ren_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Sqj1gpLj5UM8",
        "outputId": "e60f0243-dfae-4c6f-99ba-1362ca3ff6c1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "CwTd87vrUj7H",
        "outputId": "b2350680-c9c1-49ce-ef17-a3d9bef90d46"
      },
      "outputs": [],
      "source": [
        "missing_values_table(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmefXKs5pNSd"
      },
      "outputs": [],
      "source": [
        "gpu1 = df[['GPU Process Size', 'GPU Transistors', 'GPU Die Size']]\n",
        "gpu1.dropna(inplace=True)\n",
        "cpu1 = df[['CPU Process Size', 'CPU Transistors', 'CPU Die Size']]\n",
        "cpu1.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "-__m3ofBUSg8",
        "outputId": "535aba34-f3d3-4f83-f45a-545ebb8c1fdf"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=cpu1['CPU Process Size'], y=cpu1['CPU Transistors'], z=cpu1['CPU Die Size'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=cpu1['CPU Transistors'].apply(lambda x: x*0.006),\n",
        "        color=cpu1['CPU Process Size'],\n",
        "        colorscale='Viridis',\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(title='(CPU) Process Size vs Die Size vs Transistors',\n",
        "                  autosize=False,\n",
        "                  width=800,\n",
        "                  height=800,\n",
        "                  scene = dict(\n",
        "                      xaxis_title='Process Size',\n",
        "                      yaxis_title='Transistors',\n",
        "                      zaxis_title='Die Size'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "so-QbTH6mYRa",
        "outputId": "bfd2a06c-ff60-4c3d-bac2-48f3c06967a0"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=gpu1['GPU Process Size'], y=gpu1['GPU Transistors'], z=gpu1['GPU Die Size'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=gpu1['GPU Transistors'].apply(lambda x: x*0.003),\n",
        "        color=gpu1['GPU Process Size'],\n",
        "        colorscale='Viridis',\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(title='(GPU) Process Size vs Die Size vs Transistors',\n",
        "                  autosize=False,\n",
        "                  width=800,\n",
        "                  height=800,\n",
        "                  scene = dict(\n",
        "                      xaxis_title='Process Size',\n",
        "                      yaxis_title='Transistors',\n",
        "                      zaxis_title='Die Size'))\n",
        "fig.show('svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "yOH5ImbiBEMe",
        "outputId": "81aebba7-42bc-4f93-a793-bd23203cfa2e"
      },
      "outputs": [],
      "source": [
        "cpu2 = df[['CPU Brand', 'CPU Series', 'CPU Model', 'CPU Generation', 'CPU Type']]\n",
        "cpu2['Count'] = 1\n",
        "\n",
        "fig = px.sunburst(cpu2, path=['CPU Brand', 'CPU Series', 'CPU Model'], values='Count', title='Pie Chart of CPUs in our dataset',\n",
        "            color='CPU Brand', color_continuous_scale='Viridis', color_continuous_midpoint=5)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6-t6pvk9eHoq",
        "outputId": "cb87393a-b545-40a1-ffde-9fc4f4c35b14"
      },
      "outputs": [],
      "source": [
        "game = df[['Game', 'Game Resolution', 'Game Settings']]\n",
        "game['Count'] = 1\n",
        "\n",
        "game_count = game.groupby(['Game']).agg('count').reset_index().drop_duplicates()\n",
        "fig = px.bar(game_count, x='Game', y='Count')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "v99m0Q9rJYt3",
        "outputId": "49295dc7-4b35-478a-ac6f-08a196e25536"
      },
      "outputs": [],
      "source": [
        "game = df[['Game', 'Game Resolution', 'Game Settings']]\n",
        "game['Count'] = 1\n",
        "\n",
        "game_reso = game.groupby(['Game Resolution']).agg('count').reset_index().drop_duplicates()\n",
        "fig = px.bar(game_reso, x='Game Resolution', y='Count')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "NBP8ccUGfM4Q",
        "outputId": "7bc23e8a-79f9-4ebd-a9d3-724e02be66e9"
      },
      "outputs": [],
      "source": [
        "game = df[['Game', 'Game Resolution', 'Game Settings']]\n",
        "game['Count'] = 1\n",
        "\n",
        "game_sett = game.groupby(['Game Settings']).agg('count').reset_index().drop_duplicates()\n",
        "fig = px.bar(game_sett, x='Game Settings', y='Count')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M4vyKdcXPNTJ",
        "outputId": "c578a207-46b3-4418-b393-4ac9fa984705"
      },
      "outputs": [],
      "source": [
        "corr = df.corr()\n",
        "\n",
        "fig = go.Figure(data=go.Heatmap(z=corr, x=corr.columns, y=corr.columns,\n",
        "                                xgap=1, ygap=1, colorscale='Viridis'),\n",
        "                layout=go.Layout(title_text='Correlation Plot', height=1000,\n",
        "                                 yaxis_autorange='reversed'))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI7Y9Ow9Zr4F"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN55ArCCzN-_"
      },
      "outputs": [],
      "source": [
        "cpu_years = pd.read_excel('/content/gdrive/MyDrive/Capstone/cpu_names.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "14begqPMzGOY",
        "outputId": "c00c32cd-cdbe-4078-e234-4af3fb607d30"
      },
      "outputs": [],
      "source": [
        "cpu_detail_cols = ['CPU Brand', 'CPU Model', 'CPU Series', 'CPU Generation', 'CPU Cores']\n",
        "\n",
        "cpu_years['CPU Name'] = cpu_years['CPU Name'].apply(lambda x:x.replace('-', ' '))\n",
        "# cpu_years.drop(['month'], axis=1, inplace=True)\n",
        "cpu = pd.merge(df[cpu_detail_cols + ['CPU Name', 'CPU Transistors']], cpu_years, how='left', on='CPU Name')\n",
        "cpu = cpu[~cpu['CPU Transistors'].isna() & ~cpu['CPU Generation'].isna()] #dropping na transistors\n",
        "\n",
        "cpu.drop(['Unnamed: 3'], axis=1, inplace=True)\n",
        "numeric_cols = ['CPU Transistors', 'CPU Generation']\n",
        "cpu[numeric_cols] = cpu[numeric_cols].apply(pd.to_numeric)\n",
        "\n",
        "cpu.dropna(inplace = True)\n",
        "cpu = cpu.drop_duplicates()\n",
        "cpu['Adjusted Transistors'] = cpu['CPU Transistors']/cpu['CPU Cores']\n",
        "cpu['Adjusted Transistors'] = cpu['Adjusted Transistors'].apply(int)\n",
        "\n",
        "cpu.sort_values('CPU Release Year')\n",
        "\n",
        "temp = cpu.copy()\n",
        "new_cols = [x.replace(' ', '_') for x in cpu.columns]\n",
        "print(new_cols)\n",
        "temp.columns = new_cols\n",
        "temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql58JQxEb6lz"
      },
      "outputs": [],
      "source": [
        "out = sqldf('''\n",
        "\n",
        "    select max(Adjusted_Transistors) as Max_transistors, count(Adjusted_Transistors) as Models_released,\n",
        "    avg(Adjusted_Transistors) as Avg_transistors,\n",
        "    case when month < 1 then CPU_Release_Year - 1 \n",
        "    when month > 9 then CPU_Release_Year + 1\n",
        "    else CPU_Release_Year\n",
        "    end as new_year\n",
        "    from temp group by new_year\n",
        "\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTk2oSc7b6lz"
      },
      "outputs": [],
      "source": [
        "out['Double_Transistors'] = 2 * out['Max_transistors']\n",
        "out['Actual_Transistors'] = out['Max_transistors'].shift(-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abh1BVs6b6lz"
      },
      "outputs": [],
      "source": [
        "out = out.replace(out.iloc[13][0], 1200) \n",
        "out = out.replace(out.iloc[6][0], 1303)\n",
        "out = out.replace(out.iloc[7][0], 1303)\n",
        "out = out.replace(out.iloc[11][0], 3100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "CuJ6LMMfb6lz",
        "outputId": "da4eba58-de2d-487f-bb14-452866daa37f"
      },
      "outputs": [],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J01zSCakb6lz"
      },
      "outputs": [],
      "source": [
        "stat1, p1 = stats.ks_2samp(out['Actual_Transistors'][:-2], out['Double_Transistors'][:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVWDlI0Jb6lz"
      },
      "outputs": [],
      "source": [
        "stat2, p2 = stats.mannwhitneyu(out['Actual_Transistors'][:-2], out['Double_Transistors'][:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Of9G2V2bEFo"
      },
      "outputs": [],
      "source": [
        "n1 = 12\n",
        "n2 = 12\n",
        "mu = (n1*n2)/2\n",
        "sigma = math.sqrt((n1*n2)*(n1+n2+1)/12)\n",
        "z = (stat2 - mu)/sigma\n",
        "r = abs(z)/math.sqrt(n1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MizbDMlibEIS",
        "outputId": "2fbe5e4b-da1b-4ea3-a6c4-6f93fd6809db"
      },
      "outputs": [],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjSE2QpZb6lz"
      },
      "outputs": [],
      "source": [
        "kde_df = out[['Actual_Transistors', 'Double_Transistors']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "c1TSiaRfb6lz",
        "outputId": "f47abfa2-e8b3-4423-e334-df515d0f0e88"
      },
      "outputs": [],
      "source": [
        "ax = kde_df.plot.kde()\n",
        "plt.xlabel('Transistors')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Comparison of Distribution Between Actual Transistors and Double Transistors')\n",
        "plt.savefig('KDE Plot Of Distributions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rejDJp0WyRa"
      },
      "outputs": [],
      "source": [
        "one = out['Double_Transistors'][:-2]\n",
        "two = out['Actual_Transistors'][:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "w88M6gdFb6lz",
        "outputId": "1fde9299-b308-4ca0-abb7-e7a31a022b57"
      },
      "outputs": [],
      "source": [
        "X = out['new_year'][:-2]\n",
        "X_axis = np.arange(len(X))\n",
        "plt.bar(X_axis - 0.2, one, 0.4, label = 'Double_Transistors')\n",
        "plt.bar(X_axis + 0.2, two, 0.4, label = 'Actual_Transistors')\n",
        "plt.xticks(X_axis, X)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Transistors')\n",
        "plt.title('Comparison of Distribution Between Actual Transistors and Double Transistors')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Bar Plot Of Distributions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52zCOGWQb6l0"
      },
      "outputs": [],
      "source": [
        "errorBar_df = out.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm3hkFR8b6l0"
      },
      "outputs": [],
      "source": [
        "errorBar_df['Errors'] = abs(errorBar_df['Double_Transistors'] - errorBar_df['Actual_Transistors'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "BhY_u3Xxb6l0",
        "outputId": "611c82da-96d3-4393-c188-96aa378b5f52"
      },
      "outputs": [],
      "source": [
        "errorBar_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFTU3Piib6l0",
        "outputId": "42476043-9ad7-46b5-cd2c-10b4603bdc0a"
      },
      "outputs": [],
      "source": [
        "sem_Actual = out['Actual_Transistors'].std() / math.sqrt(12)\n",
        "sem_Actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1QsBarKb6l0",
        "outputId": "a56ba901-0330-4c36-fce5-9a5c707c8e2e"
      },
      "outputs": [],
      "source": [
        "sem_Expected = out['Double_Transistors'].std() / math.sqrt(12)\n",
        "sem_Expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "vLFKW_Kcb6l0",
        "outputId": "6ea0d214-2915-4e2d-93b1-fe22743f7462"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "ax.bar(errorBar_df['new_year'], errorBar_df['Actual_Transistors'],\n",
        "       yerr=sem_Actual,\n",
        "       align='center',\n",
        "       alpha=0.5,\n",
        "       ecolor='black',\n",
        "       capsize=10)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Actual Number of Transistors')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "BWeGxvwHb6l0",
        "outputId": "efbdc439-0be5-4947-e456-b6db164eaec5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "ax.bar(errorBar_df['new_year'], errorBar_df['Double_Transistors'],\n",
        "       yerr=sem_Expected,\n",
        "       align='center',\n",
        "       alpha=0.5,\n",
        "       ecolor='black',\n",
        "       capsize=10)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Expected Number of Transistors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NRB2n-Ba8FN"
      },
      "source": [
        "## Data Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufk6Yl3eHfZf"
      },
      "outputs": [],
      "source": [
        "based_col = ['CPU Brand', 'CPU Model', 'CPU Series', 'CPU Generation']\n",
        "\n",
        "geometric_cols = ['CPU Transistors']\n",
        "linear_cols = ['CPU Die Size']\n",
        "step_cols = []\n",
        "\n",
        "# Geometric Imputation\n",
        "if geometric_cols:\n",
        "    for impute_col in geometric_cols:\n",
        "        temp = df[based_col + [impute_col]].dropna(inplace=False)\n",
        "        temp[impute_col] = pd.to_numeric(temp[impute_col])\n",
        "        index = df[df[impute_col].isnull()].index.tolist()\n",
        "\n",
        "        value = temp.groupby(based_col).agg('mean').reset_index().to_dict('split')['data']\n",
        "        value_keys = [val[:4] for val in value]\n",
        "        for ind in tqdm(index):\n",
        "\n",
        "            key = tuple(df.loc[ind, based_col].values)\n",
        "            previous = [val for val in value if key[:3] == tuple(val[:3])]\n",
        "            if not previous:\n",
        "                df.drop(ind, axis=0, inplace=True)\n",
        "                continue\n",
        "            gen = [int(p[3]) for p in previous]\n",
        "            impute = [int(p[-1]) for p in previous]    \n",
        "\n",
        "            if list(key) in value_keys:\n",
        "                df.loc[ind, impute_col] = [val for val in value if key[:4] == tuple(val[:4])][0][-1]\n",
        "\n",
        "            else:\n",
        "                if int(key[3]) > min(gen) and int(key[3]) < max(gen):\n",
        "                    geom = np.geomspace(impute[gen.index(min(gen))],\n",
        "                                        impute[gen.index(max(gen))],\n",
        "                                        max(gen) - min(gen) + 1)\n",
        "                    df.loc[ind, impute_col] = geom[int(key[-1])-min(gen)]\n",
        "\n",
        "                if int(key[3]) < min(gen):\n",
        "                    gap = min(gen) - int(key[3])\n",
        "                    val = impute[gen.index(min(gen))]\n",
        "                    for i in range(gap): val /= 2\n",
        "                    df.loc[ind, impute_col] = val\n",
        "                \n",
        "                else:\n",
        "                    gap = int(key[3]) - max(gen)\n",
        "                    val = impute[gen.index(min(gen))]\n",
        "                    for i in range(gap): val *= 2\n",
        "                    df.loc[ind, impute_col] = val\n",
        "\n",
        "\n",
        "# Linear Imputation\n",
        "if linear_cols:\n",
        "    for impute_col in linear_cols:\n",
        "        temp = df[based_col + [impute_col]].dropna(inplace=False)\n",
        "        temp[impute_col] = pd.to_numeric(temp[impute_col])\n",
        "        index = df[df[impute_col].isnull()].index.tolist()\n",
        "\n",
        "        value = temp.groupby(based_col).agg('mean').reset_index().to_dict('split')['data']\n",
        "        value_keys = [val[:4] for val in value]\n",
        "        for ind in tqdm(index):\n",
        "\n",
        "            key = tuple(df.loc[ind, based_col].values)\n",
        "            previous = [val for val in value if key[:3] == tuple(val[:3])]\n",
        "            if not previous:\n",
        "                df.drop(ind, axis=0, inplace=True)\n",
        "                continue\n",
        "            gen = [int(p[3]) for p in previous]\n",
        "            impute = [int(p[-1]) for p in previous]    \n",
        "\n",
        "            if list(key) in value_keys:\n",
        "                df.loc[ind, impute_col] = [val for val in value if key[:4] == tuple(val[:4])][0][-1]\n",
        "\n",
        "            else:\n",
        "                lr = LinearRegression()\n",
        "                lr.fit(np.array(gen).reshape(-1, 1), np.array(impute).reshape(-1, 1))\n",
        "                df.loc[ind, impute_col] = lr.predict([[7]])[0][0]\n",
        "\n",
        "\n",
        "# Step Imputation\n",
        "if step_cols:\n",
        "    for impute_col in step_cols:\n",
        "        temp = df[based_col + [impute_col]].dropna(inplace=False)\n",
        "        temp[impute_col] = pd.to_numeric(temp[impute_col])\n",
        "        index = df[df[impute_col].isnull()].index.tolist()\n",
        "\n",
        "        value = temp.groupby(based_col).agg('mean').reset_index().to_dict('split')['data']\n",
        "        value_keys = [val[:4] for val in value]\n",
        "        for ind in tqdm(index):\n",
        "\n",
        "            key = tuple(df.loc[ind, based_col].values)\n",
        "            previous = [val for val in value if key[:3] == tuple(val[:3])]\n",
        "            if not previous:\n",
        "                df.drop(ind, axis=0, inplace=True)\n",
        "                continue\n",
        "            gen = [int(p[3]) for p in previous]\n",
        "            impute = [int(p[-1]) for p in previous]    \n",
        "\n",
        "            if list(key) in value_keys:\n",
        "                df.loc[ind, impute_col] = [val for val in value if key[:4] == tuple(val[:4])][0][-1]\n",
        "\n",
        "            else:\n",
        "                steps = np.linspace(impute[gen.index(min(gen))],\n",
        "                                    impute[gen.index(max(gen))],\n",
        "                                    max(gen) - min(gen) + 1)\n",
        "                step = step[1] - step[0]\n",
        "                if int(key[3]) > min(gen) and int(key[3]) < max(gen):\n",
        "                    df.loc[ind, impute_col] = steps[int(key[-1])-min(gen)]\n",
        "\n",
        "                if int(key[3]) < min(gen):\n",
        "                    gap = min(gen) - int(key[3])\n",
        "                    val = impute[gen.index(min(gen))]\n",
        "                    for i in range(gap): val -= step\n",
        "                    df.loc[ind, impute_col] = val\n",
        "                \n",
        "                else:\n",
        "                    gap = int(key[3]) - max(gen)\n",
        "                    val = impute[gen.index(min(gen))]\n",
        "                    for i in range(gap): val += step\n",
        "                    df.loc[ind, impute_col] = val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "diUY-dDuvGiT",
        "outputId": "781bf54f-9ee0-4380-cb63-eebf7b990471"
      },
      "outputs": [],
      "source": [
        " missing_values_table(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341r9MaJbBFR"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dd7218b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Capstone/transformed_fps.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d6051d9"
      },
      "outputs": [],
      "source": [
        "drop_cols = ['id', 'CPU Name', 'GPU Name','GPU Open GL','CPU Model','Dataset']\n",
        "label_cols = ['CPU Brand', 'CPU Series',\n",
        "              'CPU Type', 'CPU Multiplier Unlocked',\n",
        "              'GPU Architecture', 'GPU Bus', 'GPU Memory Type',\n",
        "              'GPU Open CL','GPU Shader Model', 'GPU Vulkan', 'Game', 'GPU Direct X', 'Game Settings']\n",
        "\n",
        "auto_ordinal_cols = ['Game Resolution', 'CPU Base Clock'] \n",
        "df = df.drop(drop_cols, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eCw5GcV1Tzz"
      },
      "source": [
        "### Mean Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuB1M1ePMHcN"
      },
      "outputs": [],
      "source": [
        "for label in label_cols:\n",
        "  mean = df['FPS'].mean()\n",
        "  agg = df.groupby(label)['FPS'].agg(['count', 'mean'])\n",
        "  counts = agg['count']\n",
        "  means = agg['mean']\n",
        "  weight = 100\n",
        "  smooth = (counts*means+weight*mean)/(counts+weight)\n",
        "  df.loc[:,label] = df[label].map(smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuI7Vs3P9rHL"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cztTlug5Hgcv"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2171449f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor(n_estimators=200, criterion='mse', \n",
        "                            max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                            max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                            bootstrap=True, oob_score=False, n_jobs=-1, \n",
        "                            random_state=R_STATE, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
        "df1=df.drop(['FPS'],axis=1)                           \n",
        "X = df1\n",
        "y = df['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "rfr.fit(X_train, y_train) \n",
        "prediction = rfr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, prediction)\n",
        "\n",
        "print(f'MSE is {mse}')\n",
        "print(f'RMSE is {mse ** 0.5}')\n",
        "print(f'R2 score is {r2_score(y_test, prediction)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW5l9xT6Hro6"
      },
      "source": [
        "### Scatter Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b29d2819"
      },
      "outputs": [],
      "source": [
        "# plt.scatter(prediction, prediction - y_test, c='green', marker='s', label='Test data')\n",
        "# plt.xlabel('Predicted values')\n",
        "# plt.ylabel('Residuals')\n",
        "# plt.legend(loc='upper left')\n",
        "# plt.hlines(y=0, xmin=0, xmax=1000, lw=2, color='red')\n",
        "# plt.xlim([0, 1000])\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4aJ2VOH-4y"
      },
      "source": [
        "### Feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad855cda"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importance(importance, names, model_type):\n",
        "    feature_importance = np.array(importance)\n",
        "    feature_names = np.array(names)\n",
        "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "    fi_df = pd.DataFrame(data)\n",
        "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'][:20])\n",
        "    plt.title(model_type + ' FEATURE IMPORTANCE')\n",
        "    plt.xlabel('FEATURE IMPORTANCE')\n",
        "    plt.ylabel('FEATURE NAMES')\n",
        "\n",
        "plot_feature_importance(rfr.feature_importances_,X_train.columns,'RANDOM FOREST')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8aPqY1efklW"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values('Game Settings')\n",
        "df['Game Settings'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lv9YosH5v8B"
      },
      "outputs": [],
      "source": [
        "df_low = df[:64573]\n",
        "df_med = df[64573:110186]\n",
        "df_high = df[110186:314478]\n",
        "df_max = df[314478:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN4cN5Yg2imQ"
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor(n_estimators=200, criterion='mse', \n",
        "                            max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                            max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                            bootstrap=True, oob_score=False, n_jobs=-1, \n",
        "                            random_state=R_STATE, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
        "\n",
        "df1 = df_low.drop(['FPS'],axis=1)                           \n",
        "X = df1\n",
        "y = df_low['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=R_STATE)\n",
        "rfr.fit(X_train, y_train) \n",
        "plot_feature_importance(rfr.feature_importances_,X_train.columns,'RANDOM FOREST low game settings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56e2c452"
      },
      "outputs": [],
      "source": [
        "df1 = df_med.drop(['FPS'],axis=1)                           \n",
        "X = df1\n",
        "y = df_med['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "rfr.fit(X_train, y_train) \n",
        "plot_feature_importance(rfr.feature_importances_,X_train.columns,'RANDOM FOREST med game settings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93a4fb6b"
      },
      "outputs": [],
      "source": [
        "df1 = df_high.drop(['FPS'],axis=1)                           \n",
        "X = df1\n",
        "y = df_high['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "rfr.fit(X_train, y_train) \n",
        "plot_feature_importance(rfr.feature_importances_,X_train.columns,'RANDOM FOREST high game settings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c50ced0"
      },
      "outputs": [],
      "source": [
        "df1 = df_max.drop(['FPS'],axis=1)                           \n",
        "X = df1\n",
        "y = df_max['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "rfr.fit(X_train, y_train) \n",
        "plot_feature_importance(rfr.feature_importances_,X_train.columns,'RANDOM FOREST max game settings')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryACrJcN4I7v"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFzLUed8r3L7"
      },
      "outputs": [],
      "source": [
        "df_= df.drop(['FPS'],axis=1)                           \n",
        "X_train, X_test, y_train, y_test = train_test_split(df_, df['FPS'], test_size = 0.30, random_state=R_STATE)\n",
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orcpConVnwBa"
      },
      "outputs": [],
      "source": [
        "pca_test = PCA(n_components=42)\n",
        "pca_test.fit(X_train_scaled)\n",
        "sns.set(style='whitegrid')\n",
        "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.axvline(linewidth=4, color='r', linestyle = '--', x=15, ymin=0, ymax=1)\n",
        "display(plt.show())\n",
        "evr = pca_test.explained_variance_ratio_\n",
        "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
        "pca_df = pd.DataFrame()\n",
        "pca_df['Cumulative Variance Ratio'] = cvr\n",
        "pca_df['Explained Variance Ratio'] = evr\n",
        "display(pca_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBDnvbQJnwES"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=15)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
        "X_test_scaled_pca = pca.transform(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO7jMxtsskrm"
      },
      "outputs": [],
      "source": [
        "pca_dims = []\n",
        "for x in range(0, len(pca_df)):\n",
        "    pca_dims.append('PCA Component {}'.format(x))\n",
        "pca_test_df = pd.DataFrame(pca_test.components_, columns=df_.columns, index=pca_dims)\n",
        "pca_test_df.head(15).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpP-GcYhskuG"
      },
      "outputs": [],
      "source": [
        "rfr.fit(X_train_scaled_pca, y_train)\n",
        "prediction = rfr.predict(X_test_scaled_pca)\n",
        "\n",
        "mse = mean_squared_error(y_test, prediction)\n",
        "print(f'MSE is {mse}')\n",
        "print(f'RMSE is {mse**0.5}')\n",
        "print(f'R2 score is {r2_score(y_test, prediction)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA2wU4XSIOup"
      },
      "outputs": [],
      "source": [
        "X_pca_big, X_pca_small, y_big, y_small = train_test_split(X_train_scaled_pca, y_train, test_size = 0.5, random_state=R_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfVpJ09Qskzn"
      },
      "outputs": [],
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_features = ['log2', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(start = 1, stop = 15, num = 15)]\n",
        "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
        "min_samples_leaf = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
        "bootstrap = [True, False]\n",
        "param_dist = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "rs = RandomizedSearchCV(rfr, \n",
        "                        param_dist, \n",
        "                        n_iter = 10, \n",
        "                        cv = 3, \n",
        "                        verbose = 1, \n",
        "                        n_jobs=-1, \n",
        "                        random_state=R_STATE)\n",
        "rs.fit(X_pca_small, y_small)\n",
        "rs.best_params_\n",
        "# {'n_estimators': 300,\n",
        "# 'min_samples_split': 12,\n",
        "# 'min_samples_leaf': 23,\n",
        "# 'max_features': 'log2',\n",
        "# 'max_depth': 14,\n",
        "# 'bootstrap': False}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5-ROUXtnwHD"
      },
      "outputs": [],
      "source": [
        "rs_df = pd.DataFrame(rs.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\n",
        "rs_df = rs_df.drop([\n",
        "            'mean_fit_time', \n",
        "            'std_fit_time', \n",
        "            'mean_score_time',\n",
        "            'std_score_time', \n",
        "            'params', \n",
        "            'split0_test_score', \n",
        "            'split1_test_score', \n",
        "            'split2_test_score', \n",
        "            'std_test_score'],\n",
        "            axis=1)\n",
        "rs_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFdKYBXinwKE"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(ncols=3, nrows=2)\n",
        "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
        "fig.set_size_inches(30,25)\n",
        "sns.barplot(x='param_n_estimators', y='mean_test_score', data=rs_df, ax=axs[0,0], color='lightgrey')\n",
        "# axs[0,0].set_ylim([.83,.93])\n",
        "axs[0,0].set_title(label = 'n_estimators', size=30, weight='bold')\n",
        "sns.barplot(x='param_min_samples_split', y='mean_test_score', data=rs_df, ax=axs[0,1], color='coral')\n",
        "# axs[0,1].set_ylim([.85,.93])\n",
        "axs[0,1].set_title(label = 'min_samples_split', size=30, weight='bold')\n",
        "sns.barplot(x='param_min_samples_leaf', y='mean_test_score', data=rs_df, ax=axs[0,2], color='lightgreen')\n",
        "# axs[0,2].set_ylim([.80,.93])\n",
        "axs[0,2].set_title(label = 'min_samples_leaf', size=30, weight='bold')\n",
        "sns.barplot(x='param_max_features', y='mean_test_score', data=rs_df, ax=axs[1,0], color='wheat')\n",
        "# axs[1,0].set_ylim([.88,.92])\n",
        "axs[1,0].set_title(label = 'max_features', size=30, weight='bold')\n",
        "sns.barplot(x='param_max_depth', y='mean_test_score', data=rs_df, ax=axs[1,1], color='lightpink')\n",
        "# axs[1,1].set_ylim([.80,.93])\n",
        "axs[1,1].set_title(label = 'max_depth', size=30, weight='bold')\n",
        "sns.barplot(x='param_bootstrap',y='mean_test_score', data=rs_df, ax=axs[1,2], color='skyblue')\n",
        "# axs[1,2].set_ylim([.88,.92])\n",
        "axs[1,2].set_title(label = 'bootstrap', size=30, weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-oN_9z-7bpJ"
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor(n_estimators=200, criterion='mse', \n",
        "                            max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                            max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                            bootstrap=True, oob_score=False, n_jobs=-1, \n",
        "                            random_state=R_STATE, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
        "rfr.fit(X_train_scaled_pca, y_train)\n",
        "# y_pred = rfr.predict(X_test_scaled_pca)\n",
        "# y_pred_pca = rfr.predict(X_test_scaled_pca)\n",
        "y_pred_gs = rs.best_estimator_.predict(X_test_scaled_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPlMbX5ufGVe"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(y_test, y_pred_gs)\n",
        "print(f'MSE is {mse}')\n",
        "print(f'RMSE is {mse**0.5}')\n",
        "print(f'R2 score is {r2_score(y_test, y_pred_gs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_h9XgbTdrAJ"
      },
      "source": [
        "### ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31eee32d"
      },
      "outputs": [],
      "source": [
        "X = df\n",
        "y = df['FPS']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=R_STATE) #20 epochs and 32 batch_size gives the best results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba4d63da"
      },
      "outputs": [],
      "source": [
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = df.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d953567"
      },
      "outputs": [],
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab1e0dc4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history = NN_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split = 0.2, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0995442e"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, key):\n",
        "    plt.plot(history.history[key])\n",
        "    plt.plot(history.history['val_'+key])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(key)\n",
        "    plt.legend([key, 'val_'+key])\n",
        "    plt.show()\n",
        "# Plot the history\n",
        "plot_history(history, 'mean_absolute_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "248a8d44"
      },
      "outputs": [],
      "source": [
        "predictions = NN_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b2801f1"
      },
      "outputs": [],
      "source": [
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ab81b1c"
      },
      "outputs": [],
      "source": [
        "print(mae)\n",
        "print(mse**0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a066c61e"
      },
      "outputs": [],
      "source": [
        "r2_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDlIXPLrsWBA"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXS3D2VrTk3X"
      },
      "outputs": [],
      "source": [
        "# 3d scatterplot using plotly\n",
        "Scene = dict(xaxis = dict(title  = 'Resolution'),yaxis = dict(title  = 'FPS'),zaxis = dict(title  = 'Settings'))\n",
        "labels = kproto.labels_\n",
        "trace = go.Scatter3d(x=mark_one[:, 0], y=mark_one[:, 1], z=mark_one[:, 2], mode='markers',marker=dict(color = labels, size= 10, line=dict(color= 'black',width = 10)))\n",
        "layout = go.Layout(margin=dict(l=0,r=0),scene = Scene,height = 800,width = 800)\n",
        "data = [trace]\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMhd_0kqubY7"
      },
      "source": [
        "#### DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WIbranrZqVN"
      },
      "outputs": [],
      "source": [
        "big_part, small_part = train_test_split(full_data, test_size=0.1, random_state=R_STATE)\n",
        "features_db = small_part.drop(['Game Resolution', 'FPS', 'Game Settings'], axis = 1)\n",
        "target_db = small_part[['Game Resolution', 'FPS', 'Game Settings']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dBYnGGLk07k"
      },
      "outputs": [],
      "source": [
        "lis = []\n",
        "window_size = 10000\n",
        "for i in range(len(full_data)//window_size):\n",
        "  print(i)\n",
        "  db = full_data[i*window_size:(i+1)*window_size]\n",
        "  print(db.shape)\n",
        "  features_db = db.drop(['Game Resolution', 'FPS', 'Game Settings'], axis = 1)\n",
        "  target_db = db[['Game Resolution', 'FPS', 'Game Settings']]\n",
        "  features_db_dist_matrix = gower.gower_matrix(features_db)\n",
        "  a = pd.DataFrame(features_db_dist_matrix)\n",
        "  dbs = DBSCAN(eps = 0.8, min_samples = 10).fit(a)\n",
        "  b = dbs.labels_\n",
        "  lis += list(b)\n",
        "  print(f'{i+1} out of 17 done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH5H2M9X803Z"
      },
      "outputs": [],
      "source": [
        "full_data = full_data.head(180000)\n",
        "full_data['clusters'] = lis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHKV-N0VHBv2"
      },
      "outputs": [],
      "source": [
        "# db_data = full_data.to_csv('/content/gdrive/MyDrive/Capstone/full_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BBBjSNW9RGk"
      },
      "outputs": [],
      "source": [
        "features_db = full_data.drop(['Game Resolution', 'FPS', 'Game Settings'], axis = 1)\n",
        "target_db = full_data[['Game Resolution', 'FPS', 'Game Settings']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi3U3vgw6rw_"
      },
      "outputs": [],
      "source": [
        "mark_two = target_db.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsLjj-APKqTW"
      },
      "outputs": [],
      "source": [
        "# 3d scatterplot using plotly\n",
        "Scene = dict(xaxis = dict(title  = 'Resolution'),yaxis = dict(title  = 'FPS'),zaxis = dict(title  = 'Settings'))\n",
        "labels = full_data['clusters']\n",
        "trace = go.Scatter3d(x=mark_two[:, 0], y=mark_two[:, 1], z=mark_two[:, 2], mode='markers',marker=dict(color = labels, size= 10, line=dict(color= 'black',width = 10)))\n",
        "layout = go.Layout(margin=dict(l=0,r=0),scene = Scene,height = 800,width = 800)\n",
        "data = [trace]\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFk5hzHBRhU0"
      },
      "outputs": [],
      "source": [
        "# un = []\n",
        "# eps_values = np.abs(np.linspace(0,1,100))\n",
        "# min_values = np.linspace(1,21,20).astype(int)\n",
        "# for i,eps in enumerate(eps_values[1:-1]):\n",
        "#   print(f'{i+1}')\n",
        "#   for min in min_values:\n",
        "#     dbs = DBSCAN(eps = eps, min_samples = min)\n",
        "#     dbs.fit(a)\n",
        "#     b = dbs.labels_\n",
        "#     unique, counts = np.unique(b, return_counts=True)\n",
        "#     if len(unique)<8 and len(unique)>4:\n",
        "#       un.append([eps,min,counts])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgvfOd41tK-C"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "839ac31e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('transformed_fps.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d6a014b"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "496dd9d3"
      },
      "outputs": [],
      "source": [
        "drop_cols = ['id', 'CPU Name', 'GPU Name','GPU Open GL','CPU Model','Dataset'] #GPU Open GL has only one value\n",
        "label_cols = ['CPU Brand', 'CPU Series',\n",
        "              'CPU Type', 'CPU Multiplier Unlocked',\n",
        "              'GPU Architecture', 'GPU Bus', 'GPU Memory Type',\n",
        "              'GPU Open CL','GPU Shader Model', 'GPU Vulkan', 'Game',\n",
        "              ]\n",
        "\n",
        "auto_ordinal_cols = ['Game Resolution', 'CPU Base Clock', 'GPU Direct X'] # Questionable: CPU Base Clock, \n",
        "\n",
        "#df['CPU Model'] = df['CPU Model'].replace({'X2': 0, '3': 1, 'i3': 1, '5': 2, 'i5': 2, '7': 3, 'i7': 3, '9': 4, 'Threadripper': 5})\n",
        "\n",
        "df = df.drop(drop_cols, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b317be61"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df, columns=label_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4be08b75"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2c2d09f"
      },
      "outputs": [],
      "source": [
        "enc_dict_resolution = {720:0,1080:1,1440:2}\n",
        "df['Game Resolution'] = df['Game Resolution'].map(enc_dict_resolution)\n",
        "\n",
        "enc_dict_CPU_base_clock = {100:0,133:1,200:2}\n",
        "df['CPU Base Clock'] = df['CPU Base Clock'].map(enc_dict_CPU_base_clock)\n",
        "\n",
        "df['GPU Direct X'] = df['GPU Direct X'].astype(str)\n",
        "enc_dict_direct = {'12':0,'12 Ultimate':1}\n",
        "df['GPU Direct X'] = df['GPU Direct X'].map(enc_dict_direct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac3fa484"
      },
      "outputs": [],
      "source": [
        "def plot_ROC_curve(model, xtrain, ytrain, xtest, ytest):\n",
        "\n",
        "    # Creating visualization with the readable labels\n",
        "    visualizer = ROCAUC(model)\n",
        "                                        \n",
        "    # Fitting to the training data first then scoring with the test data                                    \n",
        "    visualizer.fit(xtrain, ytrain)\n",
        "    visualizer.score(xtest, ytest)\n",
        "    visualizer.show()\n",
        "    \n",
        "    return visualizer\n",
        "\n",
        "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
        "    \n",
        "    #creating a set of all the unique classes using the actual class list\n",
        "    unique_class = set(actual_class)\n",
        "    roc_auc_dict = {}\n",
        "    for per_class in unique_class:\n",
        "        \n",
        "        #creating a list of all the classes except the current class \n",
        "        other_class = [x for x in unique_class if x != per_class]\n",
        "\n",
        "        #marking the current class as 1 and all other classes as 0\n",
        "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
        "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
        "\n",
        "        #using the sklearn metrics method to calculate the roc_auc_score\n",
        "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
        "        roc_auc_dict[per_class] = roc_auc\n",
        "\n",
        "    return roc_auc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcb5cfb7"
      },
      "outputs": [],
      "source": [
        "#full dataset\n",
        "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
        "                      warm_start=False)\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "rfc.fit(X_train, y_train) \n",
        "\n",
        "y_pred=rfc.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcd9d65e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(rfc, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8f39db4"
      },
      "outputs": [],
      "source": [
        "#with 25 components\n",
        "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
        "                      warm_start=False)\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "steps = [('pca', PCA(n_components=25)), ('m', rfc)]\n",
        "model = Pipeline(steps=steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "model.fit(X_train, y_train) \n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f89c24c9"
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f64caf6"
      },
      "outputs": [],
      "source": [
        "#with 30 components\n",
        "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=-1, oob_score=False, random_state=R_STATE, verbose=0,\n",
        "                      warm_start=False)\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "steps = [('pca', PCA(n_components=30)), ('m', rfc)]\n",
        "model = Pipeline(steps=steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "model.fit(X_train, y_train) \n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8168c4b8"
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvcB3aYZVEdK"
      },
      "outputs": [],
      "source": [
        "#lightgbm full dataset\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0oMVaQmVPHa"
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_0WN-LOVRuy"
      },
      "outputs": [],
      "source": [
        "#25 components\n",
        "\n",
        "lgbm_full = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "steps = [('pca', PCA(n_components=25)), ('m', lgbm_full)]\n",
        "model = Pipeline(steps=steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "model.fit(X_train, y_train) \n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGhxWLNCVWO_"
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4MREdAnVX7G"
      },
      "outputs": [],
      "source": [
        "#30 components\n",
        "\n",
        "lgbm_full = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=R_STATE)\n",
        "df1=df.drop(\"Game Settings\",axis=1)\n",
        "X = df1\n",
        "y = df['Game Settings']\n",
        "steps = [('pca', PCA(n_components=30)), ('m', lgbm_full)]\n",
        "model = Pipeline(steps=steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=R_STATE)\n",
        "model.fit(X_train, y_train) \n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "target_names = ['low', 'med', 'high','max']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7hVv3z9VbiD"
      },
      "outputs": [],
      "source": [
        "plot_ROC_curve(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://kritikseth.github.io/redirect\" target=\"_parent\"><img src=\"https://raw.githack.com/kritikseth/kritikseth/master/redirect.svg\" alt=\"Kritik Seth\"/></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0eCw5GcV1Tzz",
        "EW5l9xT6Hro6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
